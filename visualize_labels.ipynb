{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T11:18:06.452622Z",
     "start_time": "2025-11-14T11:18:04.022820Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def plot_label_with_video(hdf5_path, video_path, save_path, fs=None):\n",
    "    # Load respiration signal\n",
    "    with h5py.File(hdf5_path, 'r') as f:\n",
    "        signal = f['respiration'][:]\n",
    "\n",
    "    # Normalize respiration signal for drawing\n",
    "    signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))  # range 0 to 1\n",
    "\n",
    "    # Load video frames\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    if not fs:\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    else:\n",
    "        fps = fs\n",
    "\n",
    "    # Resample signal length to number of frames\n",
    "    signal = np.interp(\n",
    "        np.linspace(1, signal.shape[0], num_frames),\n",
    "        np.linspace(1, signal.shape[0], signal.shape[0]),\n",
    "        signal\n",
    "    )\n",
    "\n",
    "    out = cv2.VideoWriter(save_path, cv2.VideoWriter.fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    for i in tqdm(range(num_frames)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Draw respiration waveform segment on bottom of frame\n",
    "        wave_h = 350  # height of waveform area\n",
    "        overlay = frame.copy()\n",
    "\n",
    "        # Define waveform area\n",
    "        wave_x0 = 10\n",
    "        wave_x1 = width - 10\n",
    "        wave_y0 = height - wave_h\n",
    "        wave_y1 = height\n",
    "\n",
    "        # Add a dark background for the waveform area\n",
    "        cv2.rectangle(\n",
    "            overlay,\n",
    "            (wave_x0, wave_y0),\n",
    "            (wave_x1, wave_y1),\n",
    "            color=(0, 0, 0),   # black\n",
    "            thickness=-1       # filled rectangle\n",
    "        )\n",
    "\n",
    "        # Get signal slice around current time\n",
    "        plot_width = wave_x1 - wave_x0\n",
    "        plot_window_secs = 5  # a fixed signal window\n",
    "        plot_window_len = int(fps * plot_window_secs)\n",
    "\n",
    "        signal_chunk = signal[:i + 1]\n",
    "\n",
    "        # Limit to the most recent fixed-length window\n",
    "        if len(signal_chunk) > plot_window_len:\n",
    "            signal_chunk = signal_chunk[-plot_window_len:]\n",
    "\n",
    "        # Resample to match plot width\n",
    "        if len(signal_chunk) < 2:\n",
    "            signal_chunk = np.ones(plot_width) * signal_chunk[0] if len(signal_chunk) > 0 else np.zeros(plot_width)   \n",
    "        else:\n",
    "            signal_chunk = np.interp(\n",
    "                np.linspace(0, len(signal_chunk) - 1, plot_width),\n",
    "                np.arange(len(signal_chunk)),\n",
    "                signal_chunk\n",
    "            )\n",
    "\n",
    "        # Map signal to pixel Y coordinates\n",
    "        y_vals = wave_y1 - (signal_chunk * wave_h).astype(int)\n",
    "\n",
    "        for x in range(len(y_vals)-1):\n",
    "            cv2.line(overlay,\n",
    "                     (wave_x0 + x, y_vals[x]),\n",
    "                     (wave_x0 + x + 1, y_vals[x+1]),\n",
    "                     color=(0, 0, 255), thickness=2)\n",
    "\n",
    "        # Blend overlay\n",
    "        alpha = 0.6\n",
    "        frame = cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0)\n",
    "\n",
    "        # Write to output\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Saved video with annotations to {save_path}\")\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T11:21:11.058310Z",
     "start_time": "2025-11-14T11:21:03.408962Z"
    }
   },
   "cell_type": "code",
   "source": "# plot_label_with_video(\"example/S04_6_demo_pred.hdf5\", \"example/S04_6_demo.mp4\", \"example/S04_6_demo_waveform.mp4\")",
   "id": "44393ba62c919f5d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 608/608 [00:07<00:00, 82.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved video with annotations to example/S04_6_demo_waveform.mp4\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
